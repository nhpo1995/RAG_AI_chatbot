from haystack import Pipeline

from processing import files_to_embed
from processing.embedder import get_text_embedder
from storage.vector_store import get_document_store
# from utils.logger import setup_colored_logger
from storage.retriever import get_retriever

# logger = setup_colored_logger()


def get_answer():
    document_store = get_document_store(recreate_index=False)
    query = "1. B·∫£ng Doanh Thu B√°n H√†ng"
    pipe = Pipeline()
    pipe.add_component("embedder", get_text_embedder())
    pipe.add_component("retriever", get_retriever(top_k=10, document_store=document_store))
    pipe.connect("embedder.embedding", "retriever.query_embedding")
    result = pipe.run({"embedder": {"text": query}})
    documents = result['retriever']['documents']
    print(f"üîç S·ªë l∆∞·ª£ng documents ƒë∆∞·ª£c t√¨m th·∫•y: {len(documents)}")
    for doc in documents:
        print("------------------------------------------")
        print(f"ID: {doc.id}")
        print(f"Score: {doc.score}")
        print(f"Content:\n{doc.content}")
        print(f"doc_type: {doc.meta['category']}")
        print(f"source: {doc.meta['source']}")
        print(f"file_path: {doc.meta.get('file_path')}")

def debug_list_documents(document_store):
    print("üß™ Ki·ªÉm tra d·ªØ li·ªáu trong collection:", document_store.index)
    scroll_result = document_store._client.scroll(
        collection_name=document_store.index,
        limit=10  # ki·ªÉm tra v√†i doc tr∆∞·ªõc
    )[0]

    if not scroll_result:
        print("‚ùå Kh√¥ng c√≥ document n√†o trong collection.")
        return

    for point in scroll_result:
        content = point.payload.get("content", "")
        print("üìÑ", content[:200].replace("\n", " "), "...\n")


if __name__ == "__main__":
    document_store = get_document_store()
    debug_list_documents(document_store)
    get_answer()